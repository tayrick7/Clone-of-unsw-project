{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f307906-4ace-4ca9-a121-99ef85401ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,classification_report,make_scorer, f1_score\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn import model_selection\n",
    "from joblib import dump, load\n",
    "import mlflow.sklearn\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.tracking import MlflowClient\n",
    "from result_display import show_result,export_anomaly\n",
    "from reject_anomalies import pred_baseon_threshold,make_use_reject_anomalies\n",
    "from Feature_engineer import remove_unwanted_col,feature_engineer_steps\n",
    "from sklearn import decomposition\n",
    "from Data_preprocessing_method import apply_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00c60a05-7b45-493e-9c2b-29ad9f5598f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.read_csv(\"data/transactions_df.csv\")\n",
    "terminal_profiles_df = pd.read_csv(\"data/terminal_profiles_table.csv\")\n",
    "customer_profiles_df = pd.read_csv(\"data/customer_profiles_table.csv\")\n",
    "join_terminal = pd.merge(transactions_df, terminal_profiles_df, on='terminal_id', how='inner') #join dataset base on key value\n",
    "join_customer = pd.merge(join_terminal, customer_profiles_df, on='customer_id', how='inner')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44c258d-083e-446d-a3f1-5ca0b63aee88",
   "metadata": {},
   "source": [
    "## Download the CSV data\n",
    "https://www.kaggle.com/datasets/cgrodrigues/credit-card-transactions-synthetic-data-generation/data?select=transactions_df.csv\n",
    "\n",
    "## Store file at location\n",
    "- the location to put the file is at data folder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a2133f-c081-475a-a2ac-5a78d1338727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transaction_id', 'post_ts', 'customer_id', 'bin_x', 'terminal_id', 'amt', 'entry_mode', 'fraud', 'fraud_scenario', 'lat_terminal', 'log_terminal', 'mcc', 'mean_amount', 'std_amount', 'mean_nb_tx_per_day', 'network_id', 'bin_y', 'lat_customer', 'log_customer', 'available_terminals', 'nb_terminals']\n"
     ]
    }
   ],
   "source": [
    "print(join_customer.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffa0a36b-b0b4-4b50-b27c-c8932c5aaddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating sample file for client demo purpose\n",
    "#samle_file = transactions_df.sample(n=10000, random_state=42)\n",
    "#samle_file.to_csv('data/user_demo_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f39fd06d-4ba1-4db9-b4e3-64e2cf10c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineer step and one-hot enconding for categorical feature. \n",
    "# Stored in Feature_engineer.py\n",
    "train_X,train_y = feature_engineer_steps(join_customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38ba96fb-8eac-4e67-9da9-b87e6bc94506",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = remove_unwanted_col(train_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae4062f2-a5e7-4363-8085-cfff5f670e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_X, train_y,test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b5633ab-a1e3-476a-96b6-cea3bfeed7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_scorer(y_true, y_pred):\n",
    "    # Convert Isolation Forest's anomaly labels to binary labels\n",
    "    # Inliers are 1, converted to 0 (negative class)\n",
    "    # Outliers are -1, converted to 1 (positive class)\n",
    "    y_pred[y_pred == 1] = 0\n",
    "    y_pred[y_pred == -1] = 1\n",
    " \n",
    "    return f1_score(y_true, y_pred, pos_label=1)\n",
    "contamination_rate = 0.15 #default contamination rate 15% of data are anomalies\n",
    "clf = IsolationForest(contamination=contamination_rate,random_state=42)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be503c17-9880-4dd8-a5ac-d6700f0f7ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_model/best_model.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model using grid seach for best model, very time consuming. \n",
    "\n",
    "\n",
    "param_grid = {#'n_estimators': list(range(100, 300, 100)), #number of decision trees\n",
    "              'contamination': [0.05,0.15,0.02], #percentage of anomalies\n",
    "              'max_features': [5,9,12], \n",
    "              'bootstrap': [True],\n",
    "                #'max_samples':[10000]\n",
    "                }\n",
    "#f1sc = make_scorer(f1_score, average='macro') #using macro_avg_f1 as score\n",
    "scorer = make_scorer(custom_scorer, greater_is_better=True)\n",
    "grid_dt_estimator = model_selection.GridSearchCV(clf, \n",
    "                                                 param_grid,\n",
    "                                                 scoring=scorer, \n",
    "                                                 refit=True,\n",
    "                                                 cv=5, \n",
    "                                                 return_train_score=True)\n",
    "grid_dt_estimator.fit(X_train, y_train)\n",
    "dump(grid_dt_estimator.best_estimator_, 'saved_model/best_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7c0c7ea-840f-4d69-bc07-c3d5601d601d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14963228584024568\n",
      "{'bootstrap': True, 'contamination': 0.05, 'max_features': 9}\n"
     ]
    }
   ],
   "source": [
    "print(grid_dt_estimator.best_score_)\n",
    "print(grid_dt_estimator.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "985038ba-409d-406f-861d-e623bcfe0042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anomalyclassifier = IsolationForest(random_state=42, n_estimators=200)\n",
    "# anomalyclassifier.fit(X_train)\n",
    "# dump(anomalyclassifier, 'saved_model/best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af703243-870f-4ca8-b9fa-7fc9d75ac18f",
   "metadata": {},
   "source": [
    "## Train model with PCA option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deecd9ee-4294-438b-a393-cbcf7c0e3cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_model/best_model_PCA.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca = apply_PCA(train_X,5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, train_y, test_size=0.05, \n",
    "                                                    stratify=train_y, \n",
    "                                                    random_state=42)\n",
    "param_grid_PCA = {'n_estimators': [100,200,300], #number of decision trees\n",
    "              'contamination': [0.05,0.15,0.02], #percentage of anomalies\n",
    "              #'max_features': [5,9,12], \n",
    "              'bootstrap': [True],\n",
    "                #'max_samples':[10000]\n",
    "                }\n",
    "scorer = make_scorer(custom_scorer, greater_is_better=True)\n",
    "grid_dt_estimator_PCA = model_selection.GridSearchCV(clf, \n",
    "                                                 param_grid_PCA,\n",
    "                                                 scoring=scorer, \n",
    "                                                 refit=True,\n",
    "                                                 cv=5, \n",
    "                                                 return_train_score=True)\n",
    "grid_dt_estimator_PCA.fit(X_train, y_train)\n",
    "dump(grid_dt_estimator_PCA.best_estimator_, 'saved_model/best_model_PCA.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfa602b7-c918-4788-9bc6-5c7970ac8f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25547322764346475\n",
      "{'bootstrap': True, 'contamination': 0.05, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(grid_dt_estimator_PCA.best_score_)\n",
    "print(grid_dt_estimator_PCA.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b375ce6-15b4-4632-9152-acd9995e34ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
