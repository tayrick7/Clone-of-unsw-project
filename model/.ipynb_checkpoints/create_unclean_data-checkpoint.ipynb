{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0168cc26-e9ed-4cb6-b789-74ec2e82e834",
   "metadata": {},
   "source": [
    "*current dataset does not contain duplicate data or missing value, so for function demonstration purpose, this script is used to create unclean sample data*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea887a59-19a2-4bff-860f-4f3fe7c9a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc795cf6-b645-484d-871c-4cb90d742dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.read_csv(\"data/transactions_df.csv\")\n",
    "terminal_profiles_df = pd.read_csv(\"data/terminal_profiles_table.csv\")\n",
    "customer_profiles_df = pd.read_csv(\"data/customer_profiles_table.csv\")\n",
    "join_terminal = pd.merge(transactions_df, terminal_profiles_df, on='terminal_id', how='inner') #join dataset base on key value\n",
    "join_customer = pd.merge(join_terminal, customer_profiles_df, on='customer_id', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8fd2ada-b553-44ea-a0a6-2528c2fb75c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_rows = join_customer.sample(n=100,random_state=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b181bdf6-53c6-4e54-872b-7efea8a8fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    n = random.randint(0, 99)\n",
    "    duplicated_row = random_rows.iloc[n] \n",
    "\n",
    "    random_rows.loc[len(random_rows)] = duplicated_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55e89c98-30d4-4382-9afb-ba89d603c713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "###sample data now have 10 duplicate rows\n",
    "duplicates = random_rows.duplicated()\n",
    "print(duplicates.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63ce599f-4f06-4db4-af1c-62a6a121d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_missing = 0.1  # 10% of the data will be converted to NaNs\n",
    "\n",
    "# Calculate the number of values to replace\n",
    "total_cells = np.product(random_rows.shape)\n",
    "total_missing = int(total_cells * frac_missing)\n",
    "\n",
    "# Randomly select indices\n",
    "missing_indices = [(random.randint(0, random_rows.shape[0] - 1), random.randint(0, random_rows.shape[1] - 1)) for _ in range(total_missing)]\n",
    "\n",
    "# Make the replacements\n",
    "for idx in missing_indices:\n",
    "    random_rows.iat[idx] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24952c82-c7ab-40ca-961a-a4543c50e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data now contain missing value\n",
    "#print(random_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40e4c111-e5fa-4b67-bffc-d7c24e1b53f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_rows.to_csv('data/unclean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
