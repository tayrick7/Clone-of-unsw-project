{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c68d8922-2594-477f-bc50-dbda04aa5803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "from result_display import show_result,export_anomaly\n",
    "from reject_anomalies import pred_baseon_threshold,make_use_reject_anomalies\n",
    "from Feature_engineer import remove_unwanted_col_autoencoder, feature_engineer_steps\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from Data_preprocessing_method import apply_PCA\n",
    "from AutoEncoder_util import convert_type, transform_data, mad_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e86125e0-7ee7-48d0-bd28-5d0e5f9df97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.1\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3538dea5-3994-4a3e-90dd-9635459e0766",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.read_csv(\"data/transactions_df.csv\")\n",
    "terminal_profiles_df = pd.read_csv(\"data/terminal_profiles_table.csv\")\n",
    "customer_profiles_df = pd.read_csv(\"data/customer_profiles_table.csv\")\n",
    "join_terminal = pd.merge(transactions_df, terminal_profiles_df, on='terminal_id', how='inner') \n",
    "join_customer = pd.merge(join_terminal, customer_profiles_df, on='customer_id', how='inner')\n",
    "# 80% for training 20% for validation\n",
    "train_size = int(len(join_customer)*0.8)\n",
    "join_customer_train = join_customer.iloc[:train_size]\n",
    "\n",
    "# only normal data for training\n",
    "join_customer_normal =  join_customer_train[join_customer_train['fraud'] == 0].copy()\n",
    "\n",
    "# obtain test x with normal and fraud data\n",
    "train_X,train_y = feature_engineer_steps(join_customer)\n",
    "train_X = remove_unwanted_col_autoencoder(train_X)\n",
    "test_X = convert_type(train_X.iloc[train_size:])\n",
    "test_y = convert_type(train_y.iloc[train_size:])\n",
    "\n",
    "# obtain train data with only normal data\n",
    "train_X_normal,train_y_normal = feature_engineer_steps(join_customer_normal)\n",
    "train_X_normal = convert_type(remove_unwanted_col_autoencoder(train_X_normal))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "759a5060-35c1-454a-9ce3-3af70ef89287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split training set\n",
    "X_train, X_validate = train_test_split(train_X_normal, \n",
    "                                       test_size=0.2, \n",
    "                                       random_state=42)\n",
    "\n",
    "# transform data with normalization and min max scale\n",
    "X_train_transformed = transform_data(X_train)\n",
    "X_validate_transformed = transform_data(X_validate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "267e9697-4edb-4640-a84e-348c2b5acfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leonwu\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Autoencoder network\n",
    "input_dim = X_train_transformed.shape[1]\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 100\n",
    "autoencoder = tf.keras.models.Sequential([\n",
    "    \n",
    "    # deconstruct / encode\n",
    "    tf.keras.layers.Dense(input_dim, activation='relu', input_shape=(input_dim, )), \n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    \n",
    "    # reconstruction / decode\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(input_dim, activation='relu')\n",
    "    \n",
    "])\n",
    "autoencoder.compile(optimizer=\"adam\", \n",
    "                    loss=\"mse\",\n",
    "                    metrics=[\"acc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "997dc079-686c-4a8c-94d6-cfb53b39a848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">380</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">627</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)                  │             \u001b[38;5;34m380\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m1,280\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m136\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │              \u001b[38;5;34m72\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m144\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)                  │             \u001b[38;5;34m627\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,791</span> (22.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,791\u001b[0m (22.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,791</span> (22.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,791\u001b[0m (22.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "autoencoder.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b429cf2-8615-4845-84cb-d650cc4532ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our early stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001,\n",
    "    patience=10,\n",
    "    verbose=1, \n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "save_model = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='saved_model/autoencoder_best_weights.keras',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# callbacks argument only takes a list\n",
    "cb = [early_stop, save_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05f15657-ee95-4949-a487-e86670b60455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m4283/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 942us/step - acc: 0.4781 - loss: 0.0566\n",
      "Epoch 1: val_loss improved from inf to 0.03700, saving model to saved_model/autoencoder_best_weights.keras\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - acc: 0.4790 - loss: 0.0564 - val_acc: 0.5976 - val_loss: 0.0370\n",
      "Epoch 2/100\n",
      "\u001b[1m4312/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5741 - loss: 0.0368\n",
      "Epoch 2: val_loss improved from 0.03700 to 0.03643, saving model to saved_model/autoencoder_best_weights.keras\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.5741 - loss: 0.0368 - val_acc: 0.6237 - val_loss: 0.0364\n",
      "Epoch 3/100\n",
      "\u001b[1m4292/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5756 - loss: 0.0363\n",
      "Epoch 3: val_loss improved from 0.03643 to 0.03621, saving model to saved_model/autoencoder_best_weights.keras\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.5756 - loss: 0.0363 - val_acc: 0.6983 - val_loss: 0.0362\n",
      "Epoch 4/100\n",
      "\u001b[1m4314/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5756 - loss: 0.0362\n",
      "Epoch 4: val_loss improved from 0.03621 to 0.03617, saving model to saved_model/autoencoder_best_weights.keras\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.5756 - loss: 0.0362 - val_acc: 0.5504 - val_loss: 0.0362\n",
      "Epoch 5/100\n",
      "\u001b[1m4280/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5773 - loss: 0.0362\n",
      "Epoch 5: val_loss improved from 0.03617 to 0.03613, saving model to saved_model/autoencoder_best_weights.keras\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.5774 - loss: 0.0362 - val_acc: 0.7128 - val_loss: 0.0361\n",
      "Epoch 6/100\n",
      "\u001b[1m4314/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 984us/step - acc: 0.5842 - loss: 0.0361\n",
      "Epoch 6: val_loss improved from 0.03613 to 0.03594, saving model to saved_model/autoencoder_best_weights.keras\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.5842 - loss: 0.0361 - val_acc: 0.5451 - val_loss: 0.0359\n",
      "Epoch 7/100\n",
      "\u001b[1m4327/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 980us/step - acc: 0.5702 - loss: 0.0359\n",
      "Epoch 7: val_loss did not improve from 0.03594\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.5702 - loss: 0.0359 - val_acc: 0.3965 - val_loss: 0.0360\n",
      "Epoch 8/100\n",
      "\u001b[1m4313/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 973us/step - acc: 0.5678 - loss: 0.0359\n",
      "Epoch 8: val_loss improved from 0.03594 to 0.03583, saving model to saved_model/autoencoder_best_weights.keras\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.5678 - loss: 0.0359 - val_acc: 0.5200 - val_loss: 0.0358\n",
      "Epoch 9/100\n",
      "\u001b[1m4288/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 954us/step - acc: 0.5655 - loss: 0.0359\n",
      "Epoch 9: val_loss improved from 0.03583 to 0.03582, saving model to saved_model/autoencoder_best_weights.keras\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.5655 - loss: 0.0359 - val_acc: 0.5233 - val_loss: 0.0358\n",
      "Epoch 10/100\n",
      "\u001b[1m4282/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 992us/step - acc: 0.5657 - loss: 0.0358\n",
      "Epoch 10: val_loss did not improve from 0.03582\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.5657 - loss: 0.0358 - val_acc: 0.5016 - val_loss: 0.0358\n",
      "Epoch 11/100\n",
      "\u001b[1m4296/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 953us/step - acc: 0.5680 - loss: 0.0358\n",
      "Epoch 11: val_loss improved from 0.03582 to 0.03580, saving model to saved_model/autoencoder_best_weights.keras\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.5680 - loss: 0.0358 - val_acc: 0.5657 - val_loss: 0.0358\n",
      "Epoch 12/100\n",
      "\u001b[1m4294/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 965us/step - acc: 0.5711 - loss: 0.0358\n",
      "Epoch 12: val_loss did not improve from 0.03580\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.5711 - loss: 0.0358 - val_acc: 0.4780 - val_loss: 0.0358\n",
      "Epoch 13/100\n",
      "\u001b[1m4314/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 972us/step - acc: 0.5679 - loss: 0.0358\n",
      "Epoch 13: val_loss did not improve from 0.03580\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.5679 - loss: 0.0358 - val_acc: 0.5993 - val_loss: 0.0358\n",
      "Epoch 14/100\n",
      "\u001b[1m4326/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 992us/step - acc: 0.5658 - loss: 0.0358\n",
      "Epoch 14: val_loss improved from 0.03580 to 0.03579, saving model to saved_model/autoencoder_best_weights.keras\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.5658 - loss: 0.0358 - val_acc: 0.5960 - val_loss: 0.0358\n",
      "Epoch 15/100\n",
      "\u001b[1m4321/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 995us/step - acc: 0.5677 - loss: 0.0358\n",
      "Epoch 15: val_loss did not improve from 0.03579\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.5677 - loss: 0.0358 - val_acc: 0.5743 - val_loss: 0.0358\n",
      "Epoch 16/100\n",
      "\u001b[1m4307/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.5710 - loss: 0.0358\n",
      "Epoch 16: val_loss did not improve from 0.03579\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.5710 - loss: 0.0358 - val_acc: 0.5671 - val_loss: 0.0358\n",
      "Epoch 17/100\n",
      "\u001b[1m4296/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - acc: 0.5761 - loss: 0.0358\n",
      "Epoch 17: val_loss improved from 0.03579 to 0.03578, saving model to saved_model/autoencoder_best_weights.keras\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.5761 - loss: 0.0358 - val_acc: 0.5394 - val_loss: 0.0358\n",
      "Epoch 18/100\n",
      "\u001b[1m4287/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 979us/step - acc: 0.5783 - loss: 0.0358\n",
      "Epoch 18: val_loss did not improve from 0.03578\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.5783 - loss: 0.0358 - val_acc: 0.6432 - val_loss: 0.0358\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(\n",
    "    X_train_transformed, X_train_transformed,\n",
    "    shuffle=True,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=cb,\n",
    "    validation_data=(X_validate_transformed, X_validate_transformed)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7195ef8f-c752-4be6-8722-ada84365b889",
   "metadata": {},
   "source": [
    "## Train model with PCA option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4326c21f-0c19-45f3-836f-be9cbebc10f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply PCA\n",
    "X_train_transformed_PCA = apply_PCA(X_train_transformed,7)\n",
    "X_validate_transformed_PCA = apply_PCA(X_validate_transformed,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e71b9aa-bb2d-43fd-98ec-68f890865168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leonwu\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Autoencoder network\n",
    "input_dim = X_train_transformed_PCA.shape[1]\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 100\n",
    "autoencoder = tf.keras.models.Sequential([\n",
    "    \n",
    "    # deconstruct / encode\n",
    "    tf.keras.layers.Dense(input_dim, activation='relu', input_shape=(input_dim, )), \n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    \n",
    "    # reconstruction / decode\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(input_dim, activation='relu')\n",
    "    \n",
    "])\n",
    "autoencoder.compile(optimizer=\"adam\", \n",
    "                    loss=\"mse\",\n",
    "                    metrics=[\"acc\"])\n",
    "#autoencoder.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a3e2ef5-77ce-4b96-8543-c600845d4ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_PCA = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='saved_model/autoencoder_best_weights_PCA.keras',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# callbacks argument only takes a list\n",
    "cb_PCA = [early_stop, save_model_PCA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41bcb9a4-3942-44c9-a5a1-16b3338ae845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m4327/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 946us/step - acc: 0.5424 - loss: 0.1706\n",
      "Epoch 1: val_loss improved from inf to 0.16917, saving model to saved_model/autoencoder_best_weights_PCA.keras\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - acc: 0.5425 - loss: 0.1706 - val_acc: 0.4252 - val_loss: 0.1692\n",
      "Epoch 2/100\n",
      "\u001b[1m4291/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 965us/step - acc: 0.6507 - loss: 0.1549\n",
      "Epoch 2: val_loss improved from 0.16917 to 0.16903, saving model to saved_model/autoencoder_best_weights_PCA.keras\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.6507 - loss: 0.1549 - val_acc: 0.4162 - val_loss: 0.1690\n",
      "Epoch 3/100\n",
      "\u001b[1m4312/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 972us/step - acc: 0.6519 - loss: 0.1548\n",
      "Epoch 3: val_loss did not improve from 0.16903\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.6519 - loss: 0.1548 - val_acc: 0.3996 - val_loss: 0.1702\n",
      "Epoch 4/100\n",
      "\u001b[1m4308/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 962us/step - acc: 0.6524 - loss: 0.1549\n",
      "Epoch 4: val_loss improved from 0.16903 to 0.16809, saving model to saved_model/autoencoder_best_weights_PCA.keras\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.6524 - loss: 0.1549 - val_acc: 0.5015 - val_loss: 0.1681\n",
      "Epoch 5/100\n",
      "\u001b[1m4288/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 944us/step - acc: 0.6519 - loss: 0.1548\n",
      "Epoch 5: val_loss did not improve from 0.16809\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.6519 - loss: 0.1548 - val_acc: 0.5158 - val_loss: 0.1684\n",
      "Epoch 6/100\n",
      "\u001b[1m4309/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 961us/step - acc: 0.6502 - loss: 0.1548\n",
      "Epoch 6: val_loss did not improve from 0.16809\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.6502 - loss: 0.1548 - val_acc: 0.5318 - val_loss: 0.1687\n",
      "Epoch 7/100\n",
      "\u001b[1m4315/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 970us/step - acc: 0.6532 - loss: 0.1548\n",
      "Epoch 7: val_loss did not improve from 0.16809\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.6532 - loss: 0.1548 - val_acc: 0.5236 - val_loss: 0.1713\n",
      "Epoch 8/100\n",
      "\u001b[1m4291/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 990us/step - acc: 0.6536 - loss: 0.1548\n",
      "Epoch 8: val_loss improved from 0.16809 to 0.16768, saving model to saved_model/autoencoder_best_weights_PCA.keras\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.6535 - loss: 0.1548 - val_acc: 0.5279 - val_loss: 0.1677\n",
      "Epoch 9/100\n",
      "\u001b[1m4306/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 961us/step - acc: 0.6513 - loss: 0.1546\n",
      "Epoch 9: val_loss did not improve from 0.16768\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.6513 - loss: 0.1546 - val_acc: 0.5271 - val_loss: 0.1683\n",
      "Epoch 10/100\n",
      "\u001b[1m4302/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 975us/step - acc: 0.6534 - loss: 0.1548\n",
      "Epoch 10: val_loss did not improve from 0.16768\n",
      "\u001b[1m4330/4330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - acc: 0.6534 - loss: 0.1548 - val_acc: 0.5288 - val_loss: 0.1677\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(\n",
    "    X_train_transformed_PCA, X_train_transformed_PCA,\n",
    "    shuffle=True,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=cb_PCA,\n",
    "    validation_data=(X_validate_transformed_PCA, X_validate_transformed_PCA)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43616038-bc40-4836-9262-f1be31abc78a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
